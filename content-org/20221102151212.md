
# Table of Contents

1.  [survey](#orgcd7cb17)
2.  [2022顶会 强化学习 对话 相关文章](#orgbc3f9a5)
    1.  [2022\_[CASPI] Causal-aware Safe Policy Improvement for Task-oriented DialogueRamachandran<sub>Hashimoto</sub>\_](#orgb793c5d)
    2.  [2022<sub>CHAIVerma</sub><sub>Fu</sub>](#orga76516b)
    3.  [2022<sub>Learning</sub> as ConversationCai<sub>Wan</sub>\_](#orgbb9c95c)
    4.  [2022<sub>Anti</sub>-Overestimation Dialogue Policy Learning for Task-Completion Dialogue SystemTian<sub>Yin</sub>\_](#org563a115)
    5.  [2022<sub>A</sub> Versatile Adaptive Curriculum Learning Framework for Task-oriented DialogueZhao<sub>Qin</sub>\_](#orgf5cfe08)
    6.  [2022<sub>Adaptive</sub> Natural Language Generation for Task-oriented Dialogue viaOhashi<sub>Higashinaka</sub>\_](#orgbe370b7)
    7.  [2022<sub>Dynamic</sub> Dialogue Policy for Continual Reinforcement LearningGeishauser<sub>van</sub> Niekerk\_](#orgbf4ccf2)
    8.  [2022<sub>GPT</sub>-CRITICJang<sub>Lee</sub>\_](#org56c538a)
    9.  [2022<sub>Asking</sub> for KnowledgeLiu<sub>Yuan</sub><sub>.pdf</sub>](#org9a5c647)



<a id="orgcd7cb17"></a>

# survey

2022<sub>A</sub> Survey on Recent Advances and Challenges in Reinforcement Learning MethodsKwan<sub>Wang</sub>
A Survey on Reinforcement Learning for Dialogue SystemsGraßl
2022<sub>Survey</sub> on reinforcement learning for language processingUc-Cetina<sub>Navarro</sub>-Guerrero


<a id="orgbc3f9a5"></a>

# 2022顶会 强化学习 对话 相关文章


<a id="orgb793c5d"></a>

## 2022\_[CASPI] Causal-aware Safe Policy Improvement for Task-oriented DialogueRamachandran<sub>Hashimoto</sub>\_

Q1 论文试图解决什么问题？
离线强化学习从人类对话中学习会有偏差和泛化性差的问题

Q2 这是否是一个新的问题？
不是

Q3 这篇文章要验证一个什么科学假设？
能够通过细粒度的奖励（来自人类对话的意图）和对话策略保护机制 来改善性能和样本效率

Q4 有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？
 Dataefficient off-policy policy evaluation for reinforcement learning

Q5 论文中提到的解决方案之关键是什么？
加入了因果的奖励

Q7 用于定量评估的数据集是什么？代码有没有开源？
multiwoz2.0 and convlab
没有开源


<a id="orga76516b"></a>

## 2022<sub>CHAIVerma</sub><sub>Fu</sub>

Q1 论文试图解决什么问题？
完全用静态数据集通过离线强化学习训练对话策略，加上预训练模型进行对话生成，实现售货对话系统

Q2 这是否是一个新的问题？
不是，2017年已经有相关工作，属于 CraigslistBargain task

Q3 这篇文章要验证一个什么科学假设？
验证离线强化学习也能够用于训练任务型对话系统

Q7 用于定量评估的数据集是什么？代码有没有开源？
没有开源代码

Q10 下一步呢？有什么工作可以继续深入？
模型架构不太容易迁移到其他领域


<a id="orgbb9c95c"></a>

## 2022<sub>Learning</sub> as ConversationCai<sub>Wan</sub>\_


<a id="org563a115"></a>

## 2022<sub>Anti</sub>-Overestimation Dialogue Policy Learning for Task-Completion Dialogue SystemTian<sub>Yin</sub>\_

Q1 论文试图解决什么问题？
解决了对话策略模块用强化学习训练中，动作估值与实际不符导致训练不稳定的问题

Q2 这是否是一个新的问题？
不是

Q3 这篇文章要验证一个什么科学假设？
改善动作估值能提高收敛速度和性能

Q5 论文中提到的解决方案之关键是什么？
因为训练前期估值可信度低，在训练的前期降低最好动作的估值，随后逐渐提高最好动作估值的权重

Q7 用于定量评估的数据集是什么？代码有没有开源？
数据集:
movie-ticket booking (Li et al., 2016, 2017)
 restaurant reservation and taxi ordering (Li et al., 2018)


<a id="orgf5cfe08"></a>

## 2022<sub>A</sub> Versatile Adaptive Curriculum Learning Framework for Task-oriented DialogueZhao<sub>Qin</sub>\_

Q1 论文试图解决什么问题？
解决在强化学习中用课程学习训练对话策略时，对对话任务难度评估不可靠，对话策略对对话过程敏感的问题

Q2 这是否是一个新的问题？
不是

Q3 这篇文章要验证一个什么科学假设？
可以构建一个使用学习经验自动评估对话难度，同时自动选择需要的对话来训练的架构，来提高学习效率

Q7 用于定量评估的数据集是什么？代码有没有开源？
 MovieTicket Booking, Restaurant Reservation, Taxi Ordering (Li et al., 2016, 2018)
 没开源

Q10 下一步呢？有什么工作可以继续深入？
可以在多领域上拓展，如multiwoz


<a id="orgbe370b7"></a>

## 2022<sub>Adaptive</sub> Natural Language Generation for Task-oriented Dialogue viaOhashi<sub>Higashinaka</sub>\_


<a id="orgbf4ccf2"></a>

## 2022<sub>Dynamic</sub> Dialogue Policy for Continual Reinforcement LearningGeishauser<sub>van</sub> Niekerk\_

Q1 论文试图解决什么问题？
为了解决对话系统中对话策略，利用强化学习持续学习的问题

Q2 这是否是一个新的问题？


<a id="org56c538a"></a>

## 2022<sub>GPT</sub>-CRITICJang<sub>Lee</sub>\_

Q1 论文试图解决什么问题？
解决传统强化学习生成的对话质量差的问题，利用离线强化学习对PLM生成的对话进行引导

Q2 这是否是一个新的问题？
不是

Q7 用于定量评估的数据集是什么？代码有没有开源？
multiwoz2.0 and convlab
没有开源


<a id="org9a5c647"></a>

## 2022<sub>Asking</sub> for KnowledgeLiu<sub>Yuan</sub><sub>.pdf</sub>

